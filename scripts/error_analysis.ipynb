{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def get_train_test_fold(fold, dataset, num_splits=10):\n",
    "    assert fold < num_splits\n",
    "    \n",
    "    dataset_path = f\"../data/signals/{dataset}.csv\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=SEED)\n",
    "    for j, (train_idxs, test_idxs) in enumerate(skf.split(range(len(df)), df.objective_true)):\n",
    "        train_df, test_df = df.iloc[train_idxs], df.iloc[test_idxs]\n",
    "\n",
    "        if fold == j:\n",
    "            return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"politifact\", \"gossipcop\", \"celebrity\", \"fakenewsamt\"]:\n",
    "    mean_fnr = 0\n",
    "    mean_fpr = 0\n",
    "    mean_triggered_signals = np.zeros(19)\n",
    "    confusion_matrices = []\n",
    "    mean_f1 = 0\n",
    "    for i in range(10):\n",
    "        train_df, test_df = get_train_test_fold(i, dataset)\n",
    "        L_train = train_df.iloc[:, :19].to_numpy()\n",
    "        y_train = train_df[\"objective_true\"].to_numpy()\n",
    "        L_test = test_df.iloc[:, :19].to_numpy()\n",
    "        y_test = test_df[\"objective_true\"].to_numpy()\n",
    "\n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=2000, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "        mean_fnr += ((prediction == 0) & (y_test == 1)).sum()/(y_test == 1).sum()\n",
    "        non_zero_L = L_test.copy()\n",
    "        non_zero_L[non_zero_L == -1] = 0\n",
    "        non_zero_L\n",
    "\n",
    "        mean_fpr += ((prediction == 1) & (y_test == 0)).sum()/(y_test == 0).sum()\n",
    "\n",
    "        fn_triggered_signals = non_zero_L[((prediction == 0) & (y_test == 1))].sum(axis=0)  # triggered signals   \n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=500, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "\n",
    "        mean_f1 += f1_score(y_test, prediction, average=\"macro\")\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        sum_of_entries = np.sum(cm)\n",
    "        confusion_matrices.append(cm / sum_of_entries)\n",
    "\n",
    "    average_confusion_matrix = np.mean(confusion_matrices, axis=0) * 100\n",
    "    std_confusion_matrix = np.std(confusion_matrices, axis=0) * 100\n",
    "\n",
    "    mean_triggered_signals += fn_triggered_signals\n",
    "\n",
    "    mean_f1 /= 10\n",
    "    mean_fnr /= 10\n",
    "    mean_fpr /= 10\n",
    "    mean_triggered_signals /= 10\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"F1 Macro\", mean_f1)\n",
    "    print(\"FNR\", mean_fnr)\n",
    "    print(\"FPR\", mean_fpr)\n",
    "    labels = [f\"{average_confusion_matrix[i][j]:.1f}%\\n±{std_confusion_matrix[i][j]:.1f}%\" for i in range(2) for j in range(2)]\n",
    "    labels = [[labels[0], labels[1]], [labels[2], labels[3]]]\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.set(font_scale=5.0)\n",
    "    sns.heatmap(average_confusion_matrix, annot=labels, fmt=\"\", cmap='Blues', vmin=0, vmax=100, annot_kws={\"size\": 60})\n",
    "    if dataset == \"politifact\":\n",
    "        plt.title(\"PolitiFact\",fontweight=\"bold\")\n",
    "    elif dataset == \"gossipcop\":\n",
    "        plt.title(\"GossipCop\",fontweight=\"bold\")\n",
    "    elif dataset == \"celebritydataset\":\n",
    "        plt.title(\"Celebrity\",fontweight=\"bold\")\n",
    "    elif dataset == \"fakenewsdataset\":\n",
    "        plt.title(\"FakeNewsAMT\",fontweight=\"bold\")\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # plt.savefig(f\"../confusion_matrix_{dataset}.pdf\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "for dataset in [\"politifact\", \"gossipcop\", \"celebrity\", \"fakenewsamt\"]:\n",
    "    mean_fnr = 0\n",
    "    mean_fpr = 0\n",
    "    mean_triggered_signals = np.zeros(19)\n",
    "    confusion_matrices = []\n",
    "    mean_f1 = 0\n",
    "    for i in range(10):\n",
    "        train_df, test_df = get_train_test_fold(i, dataset)\n",
    "        L_train = train_df.iloc[:, :19].to_numpy()\n",
    "        y_train = train_df[\"objective_true\"].to_numpy()\n",
    "        L_test = test_df.iloc[:, :19].to_numpy()\n",
    "        y_test = test_df[\"objective_true\"].to_numpy()\n",
    "\n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=2000, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "        mean_fnr += ((prediction == 0) & (y_test == 1)).sum()/(y_test == 1).sum()\n",
    "        non_zero_L = L_test.copy()\n",
    "        non_zero_L[non_zero_L == -1] = 0\n",
    "        non_zero_L\n",
    "\n",
    "        mean_fpr += ((prediction == 1) & (y_test == 0)).sum()/(y_test == 0).sum()\n",
    "\n",
    "        fn_triggered_signals = non_zero_L[((prediction == 0) & (y_test == 1))].sum(axis=0)  # triggered signals   \n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=500, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "\n",
    "        mean_f1 += f1_score(y_test, prediction, average=\"macro\")\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        sum_of_entries = np.sum(cm)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    average_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    std_confusion_matrix = np.std(confusion_matrices, axis=0)\n",
    "\n",
    "    mean_triggered_signals += fn_triggered_signals\n",
    "\n",
    "    mean_f1 /= 10\n",
    "    mean_fnr /= 10\n",
    "    mean_fpr /= 10\n",
    "    mean_triggered_signals /= 10\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"F1 Macro\", mean_f1)\n",
    "    print(\"FNR\", mean_fnr)\n",
    "    print(\"FPR\", mean_fpr)\n",
    "    labels = [f\"{average_confusion_matrix[i][j]:.1f}\\n±{std_confusion_matrix[i][j]:.1f}\" for i in range(2) for j in range(2)]\n",
    "    labels = [[labels[0], labels[1]], [labels[2], labels[3]]]\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.set(font_scale=5.0)\n",
    "    sns.heatmap(average_confusion_matrix, annot=labels, fmt=\"\", cmap='Blues', vmin=average_confusion_matrix.min(), vmax=average_confusion_matrix.max(), annot_kws={\"size\": 60})\n",
    "    if dataset == \"politifact\":\n",
    "        plt.title(\"PolitiFact\",fontweight=\"bold\")\n",
    "    elif dataset == \"gossipcop\":\n",
    "        plt.title(\"GossipCop\",fontweight=\"bold\")\n",
    "    elif dataset == \"celebritydataset\":\n",
    "        plt.title(\"Celebrity\",fontweight=\"bold\")\n",
    "    elif dataset == \"fakenewsdataset\":\n",
    "        plt.title(\"FakeNewsAMT\",fontweight=\"bold\")\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # plt.savefig(f\"../confusion_matrix_{dataset}.pdf\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = {}\n",
    "for dataset in [\"gossipcop\", \"politifact\", \"celebrity\", \"fakenewsamt\"]:\n",
    "        all_preds[dataset] = []\n",
    "        for i in range(10):\n",
    "                train_df, test_df = get_train_test_fold(i, dataset)\n",
    "                L_train = train_df.iloc[:, :19].to_numpy()\n",
    "                y_train = train_df[\"objective_true\"].to_numpy()\n",
    "                L_test = test_df.iloc[:, :19].to_numpy()\n",
    "                y_test = test_df[\"objective_true\"].to_numpy()\n",
    "\n",
    "                label_model = LabelModel(cardinality=2, verbose=False)\n",
    "                label_model.fit(L_train, n_epochs=2000, log_freq=100, seed=SEED)\n",
    "                prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "                test_df[\"prediction\"] = prediction\n",
    "                all_preds[dataset].append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for dataset in [\"gossipcop\", \"politifact\", \"celebrity\", \"fakenewsamt\"]:\n",
    "    df = pd.concat(all_preds[dataset])\n",
    "    df_signals = df.iloc[:, :19]\n",
    "    df_signals[df_signals == -1] = 0\n",
    "    df_signals[\"objective_true\"] = df[\"objective_true\"]\n",
    "    df_signals[\"prediction\"] = df[\"prediction\"]\n",
    "    df = df_signals\n",
    "\n",
    "    df_fp = df[(df[\"objective_true\"] == 1) & (df[\"prediction\"] == 0)]\n",
    "    num_fp = len(df_fp)\n",
    "    df_fp = df_fp.drop([\"objective_true\", \"prediction\"], axis=1)\n",
    "    # df_fp = df_fp.sum(axis=0) / df_fp.sum(axis=0).sum() * 100\n",
    "    df_fp = df_fp.sum(axis=0) / num_fp\n",
    "    df_fp = df_fp.sort_values(ascending=False)\n",
    "\n",
    "    df_tn = df[(df[\"objective_true\"] == 1) & (df[\"prediction\"] == 1)]\n",
    "    num_tn = len(df_tn)\n",
    "    df_tn = df_tn.drop([\"objective_true\", \"prediction\"], axis=1)\n",
    "    # df_tn = df_tn.sum(axis=0) / df_tn.sum(axis=0).sum() * 100\n",
    "    df_tn = df_tn.sum(axis=0) / num_tn\n",
    "    df_tn = df_tn.sort_values(ascending=False)\n",
    "\n",
    "    # Combine true negatives and false positives\n",
    "    df = pd.concat([df_tn, df_fp], axis=1)\n",
    "    df.columns = [\"True Positives\", \"False Negatives\"]\n",
    "\n",
    "    \n",
    "    # Calculate the percentage decrease from true positives to false negatives\n",
    "    df[\"Change\"] = (np.round(df[\"True Positives\"], 1) - np.round(df[\"False Negatives\"], 1)) / np.round(df[\"True Positives\"], 1) * 100\n",
    "    \n",
    "    df = df[[\"True Positives\", \"False Negatives\", \"Change\"]]\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Concatenate all datasets into one DataFrame\n",
    "\n",
    "df = pd.concat(all_dfs, axis=1)\n",
    "df.columns = pd.MultiIndex.from_product([[\"GossipCop\", \"PolitiFact\", \"Celebrity\", \"FakeNewsAMT\"], [\"True Positives\", \"False Negatives\", \"Change\"]])\n",
    "df_mean = df.groupby(level=1, axis=1).mean()\n",
    "\n",
    "# Add the mean columns\n",
    "df[\"Mean\", \"True Positives\"] = df_mean[\"True Positives\"]\n",
    "df[\"Mean\", \"False Negatives\"] = df_mean[\"False Negatives\"]\n",
    "df[\"Mean\", \"Change\"] = ((df[\"Mean\", \"True Positives\"] - df[\"Mean\", \"False Negatives\"])) / df[\"Mean\", \"True Positives\"] * 100\n",
    "\n",
    "# Rearrange the columns\n",
    "df = df[[\"PolitiFact\", \"GossipCop\", \"FakeNewsAMT\", \"Celebrity\", \"Mean\"]]\n",
    "df = df.sort_values((\"Mean\", \"Change\"), ascending=False)\n",
    "\n",
    "# add a row that sums the value of all columns\n",
    "df.loc[\"Total\"] = df.sum()\n",
    "df.loc[\"Total\", (\"Mean\", \"Change\")] = (df.loc[\"Total\", (\"Mean\", \"True Positives\")] - df.loc[\"Total\", (\"Mean\", \"False Negatives\")]) / df.loc[\"Total\", (\"Mean\", \"True Positives\")] * 100\n",
    "df.loc[\"Total\", (\"PolitiFact\", \"Change\")] = (df.loc[\"Total\", (\"PolitiFact\", \"True Positives\")] - df.loc[\"Total\", (\"PolitiFact\", \"False Negatives\")]) / df.loc[\"Total\", (\"PolitiFact\", \"True Positives\")] * 100\n",
    "df.loc[\"Total\", (\"GossipCop\", \"Change\")] = (df.loc[\"Total\", (\"GossipCop\", \"True Positives\")] - df.loc[\"Total\", (\"GossipCop\", \"False Negatives\")]) / df.loc[\"Total\", (\"GossipCop\", \"True Positives\")] * 100\n",
    "df.loc[\"Total\", (\"Celebrity\", \"Change\")] = (df.loc[\"Total\", (\"Celebrity\", \"True Positives\")] - df.loc[\"Total\", (\"Celebrity\", \"False Negatives\")]) / df.loc[\"Total\", (\"Celebrity\", \"True Positives\")] * 100\n",
    "df.loc[\"Total\", (\"FakeNewsAMT\", \"Change\")] = (df.loc[\"Total\", (\"FakeNewsAMT\", \"True Positives\")] - df.loc[\"Total\", (\"FakeNewsAMT\", \"False Negatives\")]) / df.loc[\"Total\", (\"FakeNewsAMT\", \"True Positives\")] * 100\n",
    "df = df.round(1)\n",
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cred_signalsv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
