{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def get_train_test_fold(fold, dataset, num_splits=10):\n",
    "    assert fold < num_splits\n",
    "    \n",
    "    dataset_path = f\"../data/signals/{dataset}.csv\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=SEED)\n",
    "    for j, (train_idxs, test_idxs) in enumerate(skf.split(range(len(df)), y=df[\"objective_true\"].to_numpy())):\n",
    "        train_df, test_df = df.iloc[train_idxs], df.iloc[test_idxs]\n",
    "\n",
    "        if fold == j:\n",
    "            return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"politifact\", \"gossipcop\", \"celebrity\", \"fakenewsamt\"]:\n",
    "    mean_fnr = 0\n",
    "    mean_fpr = 0\n",
    "    mean_triggered_signals = np.zeros(19)\n",
    "    confusion_matrices = []\n",
    "    mean_f1 = 0\n",
    "    for i in range(10):\n",
    "        train_df, test_df = get_train_test_fold(i, dataset, 70)\n",
    "        L_train = train_df.iloc[:, :19].to_numpy()\n",
    "        y_train = train_df[\"objective_true\"].to_numpy()\n",
    "        L_test = test_df.iloc[:, :19].to_numpy()\n",
    "        y_test = test_df[\"objective_true\"].to_numpy()\n",
    "\n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=2000, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "        mean_fnr += ((prediction == 0) & (y_test == 1)).sum()/(y_test == 1).sum()\n",
    "        non_zero_L = L_test.copy()\n",
    "        non_zero_L[non_zero_L == -1] = 0\n",
    "        non_zero_L\n",
    "\n",
    "        mean_fpr += ((prediction == 1) & (y_test == 0)).sum()/(y_test == 0).sum()\n",
    "\n",
    "        fn_triggered_signals = non_zero_L[((prediction == 0) & (y_test == 1))].sum(axis=0)  # triggered signals   \n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=500, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "\n",
    "        mean_f1 += f1_score(y_test, prediction, average=\"macro\")\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        sum_of_entries = np.sum(cm)\n",
    "        confusion_matrices.append(cm / sum_of_entries)\n",
    "\n",
    "    average_confusion_matrix = np.mean(confusion_matrices, axis=0) * 100\n",
    "    std_confusion_matrix = np.std(confusion_matrices, axis=0) * 100\n",
    "\n",
    "    mean_triggered_signals += fn_triggered_signals\n",
    "\n",
    "    mean_f1 /= 10\n",
    "    mean_fnr /= 10\n",
    "    mean_fpr /= 10\n",
    "    mean_triggered_signals /= 10\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"F1 Macro\", mean_f1)\n",
    "    print(\"FNR\", mean_fnr)\n",
    "    print(\"FPR\", mean_fpr)\n",
    "    labels = [f\"{average_confusion_matrix[i][j]:.1f}%\\n±{std_confusion_matrix[i][j]:.1f}%\" for i in range(2) for j in range(2)]\n",
    "    labels = [[labels[0], labels[1]], [labels[2], labels[3]]]\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.set(font_scale=5.0)\n",
    "    sns.heatmap(average_confusion_matrix, annot=labels, fmt=\"\", cmap='Blues', vmin=0, vmax=100, annot_kws={\"size\": 60})\n",
    "    if dataset == \"politifact\":\n",
    "        plt.title(\"PolitiFact\",fontweight=\"bold\")\n",
    "    elif dataset == \"gossipcop\":\n",
    "        plt.title(\"GossipCop\",fontweight=\"bold\")\n",
    "    elif dataset == \"celebritydataset\":\n",
    "        plt.title(\"Celebrity\",fontweight=\"bold\")\n",
    "    elif dataset == \"fakenewsdataset\":\n",
    "        plt.title(\"FakeNewsAMT\",fontweight=\"bold\")\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # plt.savefig(f\"../confusion_matrix_{dataset}.pdf\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "for dataset in [\"politifact\", \"gossipcop\", \"celebrity\", \"fakenewsamt\"]:\n",
    "    mean_fnr = 0\n",
    "    mean_fpr = 0\n",
    "    mean_triggered_signals = np.zeros(19)\n",
    "    confusion_matrices = []\n",
    "    mean_f1 = 0\n",
    "    for i in range(10):\n",
    "        train_df, test_df = get_train_test_fold(i, dataset, 70)\n",
    "        L_train = train_df.iloc[:, :19].to_numpy()\n",
    "        y_train = train_df[\"objective_true\"].to_numpy()\n",
    "        L_test = test_df.iloc[:, :19].to_numpy()\n",
    "        y_test = test_df[\"objective_true\"].to_numpy()\n",
    "\n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=2000, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "        mean_fnr += ((prediction == 0) & (y_test == 1)).sum()/(y_test == 1).sum()\n",
    "        non_zero_L = L_test.copy()\n",
    "        non_zero_L[non_zero_L == -1] = 0\n",
    "        non_zero_L\n",
    "\n",
    "        mean_fpr += ((prediction == 1) & (y_test == 0)).sum()/(y_test == 0).sum()\n",
    "\n",
    "        fn_triggered_signals = non_zero_L[((prediction == 0) & (y_test == 1))].sum(axis=0)  # triggered signals   \n",
    "        label_model = LabelModel(cardinality=2, verbose=False)\n",
    "        label_model.fit(L_train, n_epochs=500, log_freq=100, seed=SEED)\n",
    "        prediction = label_model.predict(L_test, tie_break_policy=\"random\")\n",
    "\n",
    "        mean_f1 += f1_score(y_test, prediction, average=\"macro\")\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        sum_of_entries = np.sum(cm)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    average_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    std_confusion_matrix = np.std(confusion_matrices, axis=0)\n",
    "\n",
    "    mean_triggered_signals += fn_triggered_signals\n",
    "\n",
    "    mean_f1 /= 10\n",
    "    mean_fnr /= 10\n",
    "    mean_fpr /= 10\n",
    "    mean_triggered_signals /= 10\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"F1 Macro\", mean_f1)\n",
    "    print(\"FNR\", mean_fnr)\n",
    "    print(\"FPR\", mean_fpr)\n",
    "    labels = [f\"{average_confusion_matrix[i][j]:.1f}\\n±{std_confusion_matrix[i][j]:.1f}\" for i in range(2) for j in range(2)]\n",
    "    labels = [[labels[0], labels[1]], [labels[2], labels[3]]]\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.set(font_scale=5.0)\n",
    "    sns.heatmap(average_confusion_matrix, annot=labels, fmt=\"\", cmap='Blues', vmin=average_confusion_matrix.min(), vmax=average_confusion_matrix.max(), annot_kws={\"size\": 60})\n",
    "    if dataset == \"politifact\":\n",
    "        plt.title(\"PolitiFact\",fontweight=\"bold\")\n",
    "    elif dataset == \"gossipcop\":\n",
    "        plt.title(\"GossipCop\",fontweight=\"bold\")\n",
    "    elif dataset == \"celebritydataset\":\n",
    "        plt.title(\"Celebrity\",fontweight=\"bold\")\n",
    "    elif dataset == \"fakenewsdataset\":\n",
    "        plt.title(\"FakeNewsAMT\",fontweight=\"bold\")\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # plt.savefig(f\"../confusion_matrix_{dataset}.pdf\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cred_signalsv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
