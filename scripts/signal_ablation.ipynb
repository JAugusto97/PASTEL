{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dev_test_fold(fold, dataset, model_size, model_name=\"llama2_platypus\", num_splits=10):\n",
    "    assert fold < num_splits\n",
    "    \n",
    "    dataset_path = f\"../data/processed/{dataset}/{model_name}/{model_size}/{dataset}.csv\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=SEED)\n",
    "    for j, (train_idxs, test_idxs) in enumerate(skf.split(range(len(df)), y=df[\"objective_true\"].to_numpy())):\n",
    "        train_df, test_df = df.iloc[train_idxs], df.iloc[test_idxs]\n",
    "        print(len(train_df)/len(df), len(test_df)/len(df))\n",
    "\n",
    "        if fold == j:\n",
    "            return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_majority(row):\n",
    "    if len(row) == 1:\n",
    "        return row[0] if row[0] != -1 else np.random.choice([0, 1])\n",
    "    else:\n",
    "        # If there is a tie, randomly choose a class, else return the majority class\n",
    "        counts = row.value_counts().to_dict()\n",
    "        # get key with highest value\n",
    "        if -1 in counts:\n",
    "            del counts[-1]\n",
    "        \n",
    "        if len(counts) == 0:\n",
    "            return np.random.choice([0, 1])\n",
    "        else:\n",
    "            return max(counts, key=counts.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_sorted_by_corr = ['Document Citation', 'Sensationalism', 'Misleading about content',\n",
    "       'Evidence', 'Expert Citation', 'Emotional Valence',\n",
    "       'Reported by Other Sources', 'Clickbait', 'Source Credibility', 'Bias',\n",
    "       'Explicitly Unverified Claims', 'Polarizing Language', 'Informal Tone',\n",
    "       'Incorrect Spelling', 'Incivility', 'Personal Perspective', 'Inference',\n",
    "       'Impoliteness', 'Call to Action']\n",
    "\n",
    "signals_sorted_by_corr.reverse()\n",
    "\n",
    "all = []\n",
    "best_signals_per_dataset = {}\n",
    "for dataset in [\"politifact\", \"fakenewsamt\", \"celebrity\", \"gossipcop\"]:\n",
    "    print(dataset)\n",
    "\n",
    "    df = pd.read_csv(f\"../data/signals/{dataset}.csv\")\n",
    "\n",
    "    # cross validation loop\n",
    "    sf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    fold = 0\n",
    "    for train_index, test_index in sf.split(df, df[\"objective_true\"]):\n",
    "        df_train, df_test = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "        scores_by_num_signals = []\n",
    "        \n",
    "        random.seed()\n",
    "        y_test_gold = df_test[\"objective_true\"].to_numpy()\n",
    "\n",
    "        for i in range(1,20):\n",
    "            selected_signals = signals_sorted_by_corr[:i]\n",
    "            L_ws_train = df_train.loc[:, selected_signals].to_numpy()\n",
    "            L_ws_test = df_test.loc[:, selected_signals].to_numpy()\n",
    "\n",
    "            label_model = LabelModel(cardinality=2, device=\"cpu\", verbose=False)\n",
    "            if i < 3:  # snorkel does not allow less than 3 signals, so append two columns with abstentions\n",
    "                L_ws_train = np.concatenate([L_ws_train, np.zeros((len(L_ws_train), 3-i))-1], axis=1)\n",
    "                L_ws_test = np.concatenate([L_ws_test, np.zeros((len(L_ws_test), 3-i))-1], axis=1)\n",
    "\n",
    "            label_model.fit(L_ws_train, n_epochs=500, seed=SEED, progress_bar=False)\n",
    "            y_pred_ws = label_model.predict(L=L_ws_test, tie_break_policy=\"random\")\n",
    "            val_f1_macro = f1_score(y_test_gold, y_pred_ws, average='macro', zero_division=0)\n",
    "\n",
    "            d = {\"dataset\": dataset, \"fold\":fold, \"f1\": val_f1_macro, \"#signals\": i}\n",
    "            all.append(d)\n",
    "\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean and stf of the f1 scores for each dataset and number of signals\n",
    "df = pd.DataFrame(all)\n",
    "df_grouped = df.groupby([\"dataset\", \"#signals\"]).mean().reset_index()\n",
    "df_grouped[\"std\"] = df.groupby([\"dataset\", \"#signals\"]).std().reset_index()[\"f1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "df_grouped.loc[df_grouped[\"dataset\"] == \"politifact\", \"dataset\"] = \"PolitiFact\"\n",
    "df_grouped.loc[df_grouped[\"dataset\"] == \"gossipcop\", \"dataset\"] = \"GossipCop\"\n",
    "df_grouped.loc[df_grouped[\"dataset\"] == \"fakenewsamt\", \"dataset\"] = \"FakeNewsAMT\"\n",
    "df_grouped.loc[df_grouped[\"dataset\"] == \"celebrity\", \"dataset\"] = \"Celebrity\"\n",
    "\n",
    "# Get unique datasets\n",
    "unique_datasets = df_grouped[\"dataset\"].unique()\n",
    "fontsize=20\n",
    "# Plot each dataset with error bars\n",
    "for dataset in unique_datasets:\n",
    "    subset = df_grouped[df_grouped[\"dataset\"] == dataset]\n",
    "    # ax.errorbar(subset[\"#signals\"], subset[\"mu\"], yerr=subset[\"std_err\"], label=dataset)\n",
    "    ax.plot(subset[\"#signals\"], subset[\"f1\"], label=dataset, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('# Signals', fontsize=fontsize)\n",
    "ax.set_ylabel(\"F1 Macro\", fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlim(3, max(df[\"#signals\"]))\n",
    "ax.set_xticks([3] + list(df[\"#signals\"]))\n",
    "ax.tick_params(axis='y', labelsize=fontsize)\n",
    "ax.tick_params(axis='x', labelsize=fontsize)\n",
    "ax.set_ylim(0.30, 1.0)\n",
    "plt.yticks(np.arange(0.30, 1.1, 0.1))\n",
    "legend = ax.legend(fontsize=fontsize-5)\n",
    "legend.get_title().set_fontsize(fontsize) \n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"signal_ablation_sorted_corr_all.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cred_signalsv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
